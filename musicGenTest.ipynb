{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T01:24:49.202713Z",
     "iopub.status.busy": "2021-11-03T01:24:49.202081Z",
     "iopub.status.idle": "2021-11-03T01:24:51.815133Z",
     "shell.execute_reply": "2021-11-03T01:24:51.815517Z"
    },
    "id": "GsLFq7nsiqcq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-19 14:34:26.727626: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-19 14:34:26.727656: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Change order. Delete redundant. Replace some maybe? Explain every module.\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Dict, List, Optional, Sequence, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-03T01:24:51.820502Z",
     "iopub.status.busy": "2021-11-03T01:24:51.819644Z",
     "iopub.status.idle": "2021-11-03T01:24:51.821646Z",
     "shell.execute_reply": "2021-11-03T01:24:51.821984Z"
    },
    "id": "Efja_OtJNzAM"
   },
   "outputs": [],
   "source": [
    "# Review later\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "_SAMPLING_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice for Path, since we use Linux and Windows.\n",
    "\n",
    "data_dir = pathlib.Path('data/maestro-v2.0.0')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'maestro-v2.0.0-midi.zip',\n",
    "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip',\n",
    "      extract=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jack/.keras/datasets/maestro-v2.0.0-midi.zip'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.get_file(\n",
    "      'maestro-v2.0.0-midi.zip',\n",
    "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip',\n",
    "      extract=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# not keyword\n",
    "\n",
    "a = False\n",
    "\n",
    "if not a:\n",
    "    print('False')\n",
    "\n",
    "if a:\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our length 1282\n",
      "Number of files: 1282\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "f2 = []\n",
    "for i in glob.glob('data/maestro-v2.0.0/*/*[.mid]*'):\n",
    "    f2.append(i)\n",
    "\n",
    "print('our length', len(f2))\n",
    "print('Number of files:', len(filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.rank of    0\n",
      "0  3>\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1,2,3], [4,5,6], [8,9,0]])\n",
    "array2 = np.array([3])\n",
    "p2 = pd.DataFrame(array2)\n",
    "p = pd.DataFrame(array)\n",
    "p.head()\n",
    "\n",
    "print(p2.rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  1.0  2.0\n",
      "1  2.0  2.0  3.0\n",
      "2  3.0  3.0  1.0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(p.rank(method='max'))\n",
    "print(array.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (878845327.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [10]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(c[])\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Test of pd.Concat\n",
    "\n",
    "a = np.array([0,1])\n",
    "b = np.array([2,3])\n",
    "cList = [pd.DataFrame(a),pd.DataFrame(b)]\n",
    "c = pd.concat(cList)\n",
    "print(a)\n",
    "print(b)\n",
    "print(a+b)\n",
    "print(c)\n",
    "\n",
    "print(c[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "a = {'Pitch': [0, 1, 2], 'Lol': [3, 4, 5]}\n",
    "b = {'Pitch': [22, 33, 44], 'Lol': [55, 66, 77]}\n",
    "\n",
    "n1 = np.array(a)\n",
    "n2 = np.array(b)\n",
    "n3 = np.stack((a,b))\n",
    "print(n3[0]['Pitch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-18 22:33:34.146415: W tensorflow/core/data/root_dataset.cc:200] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_VariantDataset' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jack/Projects/MUSIC_AI/musicGenTest.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Projects/MUSIC_AI/musicGenTest.ipynb#ch0000010?line=1'>2</a>\u001b[0m dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mrange(\u001b[39m7\u001b[39m)\u001b[39m.\u001b[39mwindow(size, shift\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, drop_remainder\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Projects/MUSIC_AI/musicGenTest.ipynb#ch0000010?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m window \u001b[39min\u001b[39;00m dataset:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jack/Projects/MUSIC_AI/musicGenTest.ipynb#ch0000010?line=3'>4</a>\u001b[0m   \u001b[39mprint\u001b[39m(window\u001b[39m.\u001b[39;49mnumpy())\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Projects/MUSIC_AI/musicGenTest.ipynb#ch0000010?line=5'>6</a>\u001b[0m batched \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mflat_map(\u001b[39mlambda\u001b[39;00m x:x\u001b[39m.\u001b[39mbatch(\u001b[39m3\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jack/Projects/MUSIC_AI/musicGenTest.ipynb#ch0000010?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m batched:\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_VariantDataset' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "size = 4\n",
    "dataset = tf.data.Dataset.range(7).window(size, shift=1, drop_remainder=True)\n",
    "for window in dataset:\n",
    "  print(window.numpy())\n",
    "\n",
    "batched = dataset.flat_map(lambda x:x.batch(3))\n",
    "for batch in batched:\n",
    "  print(batch.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "np.stack((a, b), axis=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26a30f0ddadadff36fd977d59d6c3e77bff73a961c547e1d52edcd1b8ca5dde7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
